# Sistema de Logging para FastAPI Performance Benchmark

## ğŸ“‹ DescripciÃ³n General

Este proyecto incluye un sistema de logging robusto diseÃ±ado para capturar todos los eventos, mÃ©tricas y errores durante las ejecuciones diarias de benchmarking de 4 semanas.

## ğŸ—‚ï¸ Estructura de Carpetas

```
.logs/
â”œâ”€â”€ daily/                    # Logs generales diarios
â”‚   â”œâ”€â”€ 2025-11-14.log       # Logs generales del dÃ­a
â”‚   â”œâ”€â”€ 2025-11-14_config.log # ConfiguraciÃ³n utilizada
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ errors/                   # Logs de errores y advertencias
â”‚   â”œâ”€â”€ 2025-11-14_errors.log # Errores y warnings del dÃ­a
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ performance/              # Logs de rendimiento
â”‚   â”œâ”€â”€ 2025-11-14_performance.log  # MÃ©tricas de benchmarks
â”‚   â”œâ”€â”€ 2025-11-14_connectivity.log # Estados de conexiÃ³n
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ archive/                  # Logs comprimidos (>7 dÃ­as)
â”‚   â”œâ”€â”€ 2025-11-07_performance.log.gz
â”‚   â”œâ”€â”€ 2025-11-07_errors.log.gz
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md                 # Esta documentaciÃ³n
```

## ğŸ“Š Tipos de Logs

### 1. **Daily Logs** (`.logs/daily/`)
**Archivos:** `YYYY-MM-DD.log`, `YYYY-MM-DD_config.log`

Contiene todos los eventos principales:
- Inicio/fin de benchmarks
- ConfiguraciÃ³n de ejecuciÃ³n
- Progreso de pruebas
- Eventos importantes del sistema

**Ejemplo:**
```
2025-11-14 10:30:00 | benchmark.general | INFO | ================================================================================
2025-11-14 10:30:00 | benchmark.general | INFO | ğŸš€ INICIO DE BENCHMARK
2025-11-14 10:30:00 | benchmark.config | INFO | NÃºmero de pruebas: 10
2025-11-14 10:30:15 | benchmark.general | INFO | ğŸŒ INICIANDO PRUEBAS: VPS Sin Docker
```

### 2. **Error Logs** (`.logs/errors/`)
**Archivos:** `YYYY-MM-DD_errors.log`

Contiene solo errores y advertencias:
- Fallos de conexiÃ³n
- Timeouts
- Excepciones
- Comportamientos anÃ³malos

**Ejemplo:**
```
2025-11-14 10:35:42 | benchmark.errors | WARNING | Errores detectados en Heavy Computation: 5/500 requests
2025-11-14 10:45:18 | benchmark.errors | ERROR | Error de conectividad en http://138.68.233.15:8000/health
```

### 3. **Performance Logs** (`.logs/performance/`)
**Archivos:** `YYYY-MM-DD_performance.log`, `YYYY-MM-DD_connectivity.log`

Contiene mÃ©tricas detalladas:
- RPS (Requests per Second)
- Latencia (avg, p95, p99)
- Uso de CPU y memoria
- Resultado de cada request
- Estados de conectividad

**Ejemplo:**
```
2025-11-14 10:30:22 | benchmark.performance | DEBUG | Endpoint: Root Endpoint | Environment: vps_no_docker | RPS: 682.79 | Latency: 534.14ms | P95: 612.95ms | P99: 631.43ms | CPU: 48.7% | Memory: 489.01MB | Errors: 0/500
2025-11-14 10:30:25 | benchmark.connectivity | INFO | âœ… Conectividad OK: http://138.68.233.15:8000/health (23.45ms)
```

## ğŸ”„ RotaciÃ³n AutomÃ¡tica

### PolÃ­tica de RotaciÃ³n
- **Diaria:** AutomÃ¡ticamente a medianoche, se crea un nuevo archivo con la fecha del dÃ­a
- **Archivado:** Archivos de mÃ¡s de 7 dÃ­as se comprimen automÃ¡ticamente con gzip
- **CompresiÃ³n:** Reduce el tamaÃ±o en ~60-80%
- **Limpieza:** Scripts de limpieza manual disponibles

### Espacios Estimados (4 semanas)

**Por ejecuciÃ³n diaria (30 benchmarks):**
- Logs generales: ~2-5 MB
- Logs de errores: ~100-500 KB
- Logs de rendimiento: ~3-8 MB
- **Total/dÃ­a: ~5-13 MB**

**4 semanas (28 dÃ­as):**
- Total sin comprimir: ~140-360 MB
- Total comprimido: ~30-80 MB

## ğŸš€ Uso del Sistema

### 1. Ejecutar Benchmark con Logging AutomÃ¡tico

```bash
# Usar directorio de logs por defecto (.logs)
python benchmark_python.py --tests 10

# Usar directorio de logs personalizado
python benchmark_python.py --tests 10 --log-dir /path/to/logs

# Ver logs en tiempo real
tail -f .logs/daily/$(date +%Y-%m-%d).log
tail -f .logs/errors/$(date +%Y-%m-%d)_errors.log
tail -f .logs/performance/$(date +%Y-%m-%d)_performance.log
```

### 2. Analizar Logs HistÃ³ricos

```bash
# Analizar Ãºltimos 7 dÃ­as
python analyze_logs.py --days 7

# Generar reporte en formato JSON
python analyze_logs.py --days 7 --format json --output reporte_semanal.json

# Generar reporte en formato CSV
python analyze_logs.py --days 7 --format csv --output reporte_semanal.csv

# Mostrar estadÃ­sticas
python analyze_logs.py --days 14
```

### 3. Limpiar Logs Antiguos

```bash
# Vista previa de limpieza (dry-run)
python analyze_logs.py --clean --dry-run

# Comprimir y archivar logs mÃ¡s antiguos que 7 dÃ­as
python analyze_logs.py --clean --days 7
```

## ğŸ“ˆ Monitoreo de Logs

### Ver Logs en Vivo
```bash
# Terminal 1: Logs generales
watch -n 1 'tail -20 .logs/daily/$(date +%Y-%m-%d).log'

# Terminal 2: Errores recientes
watch -n 2 'tail -10 .logs/errors/$(date +%Y-%m-%d)_errors.log'

# Terminal 3: MÃ©tricas de rendimiento
watch -n 5 'tail -5 .logs/performance/$(date +%Y-%m-%d)_performance.log'
```

### Buscar Eventos EspecÃ­ficos
```bash
# Buscar errores de hoy
grep ERROR .logs/errors/$(date +%Y-%m-%d)_errors.log

# Buscar resultados de un endpoint especÃ­fico
grep "Heavy Computation" .logs/performance/$(date +%Y-%m-%d)_performance.log

# Contar fallos de conectividad
grep -c "Error de conectividad" .logs/errors/$(date +%Y-%m-%d)_errors.log

# Ver todos los RPS registrados
grep "RPS:" .logs/performance/$(date +%Y-%m-%d)_performance.log

# Buscar problemas en los Ãºltimos 2 dÃ­as
find .logs/daily -name "*.log" -mtime -2 -exec grep -l "ERROR\|WARNING" {} \;
```

## ğŸ” Ejemplo de AnÃ¡lisis Semanal

```bash
#!/bin/bash
# script_analisis_semanal.sh

FECHA=$(date +%Y-%m-%d_%H%M%S)
REPORTE="reporte_semanal_$FECHA"

echo "Generando reportes semanales..."

# AnÃ¡lisis en Markdown
python analyze_logs.py --days 7 --format markdown --output "$REPORTE.md"

# AnÃ¡lisis en JSON
python analyze_logs.py --days 7 --format json --output "$REPORTE.json"

# AnÃ¡lisis en CSV
python analyze_logs.py --days 7 --format csv --output "$REPORTE.csv"

# Resumen
echo ""
echo "ğŸ“Š Resumen de Logs Semanales"
echo "================================"
echo "Fecha: $(date)"
echo ""

# Contar eventos
echo "Errores encontrados: $(grep -r ERROR .logs/errors -d skip | wc -l)"
echo "Advertencias: $(grep -r WARNING .logs/errors -d skip | wc -l)"
echo ""

# TamaÃ±o de logs
echo "TamaÃ±o total de logs activos: $(du -sh .logs/daily .logs/errors .logs/performance 2>/dev/null | tail -1 | cut -f1)"
echo "TamaÃ±o de archivo: $(du -sh .logs/archive 2>/dev/null | cut -f1)"
echo ""

echo "âœ… Reportes generados:"
ls -lh $REPORTE.*
```

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Personalizar Niveles de Log

Editar `logging_manager.py` para ajustar niveles:

```python
# Cambiar nivel de logging para consola
handler.setLevel(logging.DEBUG)  # DEBUG, INFO, WARNING, ERROR, CRITICAL
```

### Cambiar Directorios de Logs

```python
# Usar ruta personalizada
log_manager = get_log_manager('/custom/path/.logs')
```

## âš™ï¸ ImplementaciÃ³n en Cron (Linux/Mac)

Para ejecutar automÃ¡ticamente cada dÃ­a:

```bash
# Editar crontab
crontab -e

# Agregar entrada (ejecutar diariamente a las 02:00 AM)
0 2 * * * cd /path/to/project && python benchmark_python.py --tests 10 --log-dir .logs >> cron_execution.log 2>&1
```

## ğŸªŸ ImplementaciÃ³n en Task Scheduler (Windows)

```batch
# Script: run_benchmark.bat
@echo off
cd C:\Users\YourUser\Projects\SistemasOperativos
python benchmark_python.py --tests 10 --log-dir .logs
```

Luego crear una tarea programada en Windows Task Scheduler.

## ğŸ“‹ Checklist de Mantenimiento

- [ ] **Diario:** Revisar `.logs/errors/` para nuevos errores
- [ ] **Diario:** Verificar logs de conectividad en `.logs/performance/`
- [ ] **Semanal:** Generar reporte semanal con `analyze_logs.py`
- [ ] **Semanal:** Revisar tendencias de rendimiento
- [ ] **Mensual:** Hacer backup de `.logs/` antes de limpieza
- [ ] **Mensual:** Comprimir y archivar logs antiguos
- [ ] **Mensual:** Revisar uso total de espacio en disco

## ğŸ“š Recursos Adicionales

- MÃ³dulo LogManager: `logging_manager.py`
- Script de anÃ¡lisis: `analyze_logs.py`
- Benchmarking: `benchmark_python.py`
- ArtÃ­culo cientÃ­fico: `ARTICULO_CIENTIFICO_FASTAPI_PERFORMANCE.md`

## â“ Preguntas Frecuentes

**P: Â¿DÃ³nde se guardan los logs?**
R: En la carpeta `.logs/` en el directorio raÃ­z del proyecto, o en la ruta especificada con `--log-dir`.

**P: Â¿Cada cuÃ¡nto se rotan los logs?**
R: AutomÃ¡ticamente cada medianoche. Se crea un nuevo archivo con la fecha actual.

**P: Â¿CuÃ¡nto espacio necesito para 4 semanas?**
R: Aproximadamente 140-360 MB sin comprimir, o 30-80 MB comprimidos.

**P: Â¿CÃ³mo recupero un log eliminado?**
R: Los logs nunca se eliminan, solo se comprimen a `.logs/archive/`. Puedes descomprimirlos con: `gzip -d archivo.log.gz`

**P: Â¿Puedo cambiar la ubicaciÃ³n de los logs?**
R: SÃ­, usa `--log-dir /nueva/ruta` al ejecutar el benchmark.

---

**Ãšltima actualizaciÃ³n:** 14-11-2025  
**VersiÃ³n:** 1.0  
**Autor:** Irving B.
